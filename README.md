### Курс Проектирование систем машинного обучения
### Тема: Поиск товаров для электронной коммерции (12)
### Студент: Ивченко Анна
### Группа:214


---

## **Введение и постановка задачи**

Проектируется система ранжирования товаров для электронной коммерции на основе текстового запроса пользователя. Система должна обеспечивать персонализированную и релевантную выдачу товаров, сочетая семантическое понимание запроса с бизнес-приоритетами (коэффициент конверсии, маржа, популярность).

Система должна работать под высокой нагрузкой, масштабироваться под большое количество пользователей и обеспечивать стабильную работу в условиях пиковых нагрузок.

### **Бизнес-цели:**

1. **Увеличение конверсии поисковых запросов в покупки**  
   Повысить процент пользователей, которые совершают покупку после использования поиска, с текущих 15% до 25% за счет улучшения релевантности выдачи и учёта коммерческих метрик.

2. **Увеличение средней маржи заказа**  
   Повысить среднюю маржу товаров в поисковой выдаче на 12% за счёт учёта рентабельности товаров при ранжировании, не снижая при этом пользовательское удовлетворение.

3. **Увеличение вовлеченности пользователей**  
   Увеличить количество поисковых сессий на пользователя в месяц с 8 до 12 за счёт повышения удовлетворённости качеством поиска и релевантности результатов.

### **Требования к системе:**

- **Задержка (latency) ответа** не должна превышать **190 мс**.
- **Пропускная способность:** система должна обслуживать **3,858,438 активных пользователей в день (DAU)**, с пиковой нагрузкой в **12,051 запросов в секунду (RPS)**.
- **Точность ранжирования:** NDCG@10 (Normalized Discounted Cumulative Gain) не ниже 0.85.
- **Масштабируемость:** система должна горизонтально масштабироваться при увеличении нагрузки.
- **Отказоустойчивость:** доступность системы не менее 99.9% (до 8.7 часов простоя в год).
- **Безопасность:** защита персональных данных пользователей, контроль доступа к информации.

---

## **Часть 1: Формулировка ML-задачи и выбор модели**

### **1. Определение ML-задачи**

**Задача:** Ранжирование товаров в электронной коммерции на основе текстового запроса пользователя.

- **Формулировка:** Это задача **Learning to Rank (LtR)**, где модель обучается ранжировать список товаров по убыванию релевантности запросу, учитывая как текстовые признаки, так и бизнес-метрики.
- **Целевая переменная:** Идеальным таргетом была бы **позиция клика/покупки в выдаче** для пары (запрос, товар). На практике часто используют:
  1. **Бинарный таргет:** Клик/покупка (1) или отсутствие взаимодействия (0).
  2. **Мультиклассовый таргет:** Уровень релевантности (например, 0 – нерелевантен, 1 – релевантен, 2 – очень релевантен), определяемый экспертами или на основе поведения пользователей (покупка > клик > просмотр).
- **Необходимые данные:**
  - **Исторические данные поиска:** Запросы пользователей, выдача товаров, клики, покупки.
  - **Текстовые данные:** Названия, описания, характеристики товаров.
  - **Бизнес-метрики товаров:** Цена, маржа, рейтинг, коэффициент конверсии (CVR), популярность.
  - **Контекстуальные данные:** Категория товара, сезонность, локация пользователя.

### **2. Выбор модели**

Рассматриваем две популярные архитектуры для задач ранжирования:

**1. Двухбашенная нейросетевая модель (Two-Tower Neural Network):**
- **Архитектура:** Две отдельные нейросетевые "башни" — одна для кодирования запроса (например, на основе BERT), другая для кодирования товара (на основе его текстовых и числовых признаков). Релевантность вычисляется как косинусное сходство или скалярное произведение полученных эмбеддингов.
- **Преимущества:**
  - Эффективность на инференсе: эмбеддинги товаров можно предвычислить и хранить в векторной БД, что позволяет быстро находить ближайших соседей для запроса.
  - Хорошо масштабируется на большие каталоги товаров (миллионы).
  - Позволяет легко комбинировать разнородные признаки товара.
- **Недостатки:**
  - Моделирует попарное взаимодействие, но не глобальное ранжирование всего списка.
  - Сложнее напрямую оптимизировать под позиционные метрики (например, NDCG).

**2. Gradient Boosting Decision Trees (GBDT) для ранжирования (например, LambdaMART):**
- **Архитектура:** Ансамбль деревьев решений, оптимизированный непосредственно под метрики ранжирования (например, NDCG) через алгоритм LambdaMART.
- **Преимущества:**
  - Высокая точность, особенно при работе с табличными данными (числовые и категориальные признаки).
  - Прямая оптимизация под метрики ранжирования.
  - Хорошая интерпретируемость (важность признаков).
- **Недостатки:**
  - Менее эффективна для работы с "сырым" текстом (требует отдельного этапа извлечения текстовых эмбеддингов).
  - Инференс может быть медленнее по сравнению с Two-Tower, если нужно пересчитывать ранжирование для большого списка кандидатов.

**Выбор:** Для системы электронной коммерции, где критичны **низкая задержка (<190 мс)** и **обслуживание миллионов товаров**, выбираем **Two-Tower архитектуру**. Это позволит:
1. Достичь требуемой задержки за счет предвычисления эмбеддингов товаров и быстрого поиска по индексу.
2. Эффективно комбинировать текстовую релевантность (через эмбеддинги BERT) с бизнес-метриками (через входные признаки башни товара).
3. Легко масштабировать систему.

---

## **Часть 2: Проектирование архитектуры**

Ниже представлены диаграммы ключевых компонентов системы. Они выполнены в стиле, аналогичном примеру отчета.

### **1. Высокоуровневая архитектура системы**

![Высокоуровневая архитектура системы](1.high_lvl.png)

**Описание:**
- **Пользователь** отправляет поисковый запрос через веб- или мобильное приложение.
- **API Gateway** принимает запрос, маршрутизирует его и управляет аутентификацией.
- **Search & Ranking Service** – основное микросервисное приложение, реализующее логику поиска и ранжирования.
- **Candidate Retrieval (Retrieval Service):** Быстро отбирает из каталога (миллионы) ~1000 потенциально релевантных товаров с помощью обратного индекса (Elasticsearch) или приближенного поиска соседей (Annoy, FAISS).
- **Neural Ranking Service (Two-Tower Model):** Получает запрос и список кандидатов. Кодирует запрос через башню запросов, вычисляет релевантность с предвычисленными эмбеддингами товаров и выдает окончательный ранжированный список (Top-N).
- **Feature Store:** Хранит актуальные признаки товаров (эмбеддинги, цена, рейтинг, CVR), обновляемые пайплайнами.
- **Monitoring & Logging:** Prometheus, Grafana и ELK-стек для мониторинга метрик, задержек и логирования.

### **2. Архитектура Data Pipeline**

![Архитектура Data Pipeline](2.data_pipeline.png)

**Этапы:**
1. **Сбор данных (Data Ingestion):** Потоковые (Kafka) и пакетные (S3) данные: логи поиска (запросы, клики, покупки), каталог товаров, бизнес-метрики.
2. **Очистка и обогащение (Spark/Flink Jobs):** Обработка сырых логов, извлечение сессий, агрегация признаков на уровне товара (средний рейтинг, исторический CVR).
3. **Генерация признаков (Feature Engineering):**
   - **Текстовые эмбеддинги:** Пайплайн запускает предобученную модель (BERT) для генерации эмбеддингов названий/описаний товаров и сохраняет их.
   - **Числовые/категориальные признаки:** Нормализация, кодирование.
4. **Feature Store:** Обработанные и актуальные признаки товаров и запросов сохраняются для использования в обучении и инференсе.
5. **Формирование обучающей выборки:** Создание пар/троек (запрос, позитивный товар, негативный товар) из логов для задачи обучения ранжированию.

### **3. Архитектура Training Pipeline**

![Архитектура Training Pipeline](3.training_pipeline.png)

**Процесс:**
1. **Триггер:** Запуск по расписанию (ежедневно) или при изменении данных/кода.
2. **Извлечение данных:** Загрузка свежих обучающих данных из Feature Store.
3. **Обучение модели (GPU Cluster):**
   - Обучение Two-Tower модели на парах (query, item) с использованием контрасттивных (Triplet Loss) или pointwise/pairwise функций потерь.
   - Логирование экспериментов, метрик и артефактов в **MLflow**.
4. **Валидация и тестирование:** Оценка на hold-out выборке по метрикам (NDCG@10, Precision@K, Recall@K).
5. **A/B-тестирование:** Новые версии модели проходят онлайн A/B-тест на небольшом проценте трафика.
6. **Регистрация и развертывание:** Успешная модель регистрируется в **MLflow Model Registry**. После утверждения автоматически запускается пайплайн обновления **Neural Ranking Service** и пересчета эмбеддингов товаров.

### **4. Архитектура Inference Pipeline (Serving)**

![Архитектура Inference Pipeline (Serving)](4.inference_pipeline_serving.png)

**Компоненты и поток:**
1. **Load Balancer:** Распределяет входящие поисковые запросы между репликами **Search & Ranking Service**.
2. **Search & Ranking Service (в Kubernetes Pod):**
   - **Retrieval Module:** Получает запрос, обращается к **Elasticsearch/FAISS** для быстрого поиска ~1000 кандидатов по текстовому совпадению.
   - **Feature Fetching:** Для каждого кандидата загружает актуальные признаки из **Feature Store** (или локального кэша, например, **Redis**).
   - **Neural Ranking Module (Two-Tower):**
     - **Query Tower:** В реальном времени кодирует запрос в эмбеддинг.
     - **Item Tower:** Использует *предвычисленные эмбеддинги товаров*, загруженные в память или быстрый векторный индекс.
     - Вычисляет скоринг (например, косинусное сходство) для каждого кандидата.
   - **Re-ranker (опционально):** Применяет легковесные бизнес-правила (например, буст для товаров с высокой маржой в пределах похожей релевантности).
   - **Сортировка и возврат:** Товары сортируются по итоговому скорингу и возвращаются пользователю (Top-N).
3. **Кэширование (Redis):** Кэширует результаты для популярных запросов, чтобы снизить нагрузку и задержку.
4. **Масштабирование (HPA):** Horizontal Pod Autoscaler автоматически добавляет реплики сервиса при росте нагрузки (RPS).
5. **Логирование и мониторинг:** Все запросы, ответы и задержки логируются. **Prometheus** собирает системные и бизнес-метрики, **Grafana** – дашборды. **Canary Deployment** для безопасного обновления моделей.

### **5. Архитектура масштабируемости и отказоустойчивости**

![Архитектура масштабируемости и отказоустойчивости](5.Scalable and Fault-Tolerant.png)

### **6. Детализация Two-Tower модели**

![Детализация Two-Tower модели](6.two-tower_model.png)

---

## **Часть 3: Расчёты и нефункциональные требования**

### **1. Расчёт требований к хранилищу**

- **Данные логов (сырые):**
  - Предположим, каждый лог-запрос ~1 КБ.
  - Пиковая нагрузка: 12,051 RPS.
  - Объем в день: 12,051 RPS * 86400 сек * 1 КБ ≈ **997 ГБ/день**.
  - Хранение 30 дней сырых логов: ~30 ТБ.

- **Обучающие данные (обработанные):**
  - Обогащенные логи с признаками ~5 КБ на запрос.
  - Объем для 30 дней обучения: (997 ГБ/день * 5) * 30 дней ≈ **150 ТБ**.

- **Feature Store (признаки товаров):**
  - 10 млн товаров * (768-размер эмбеддинга + 100 числовых признаков) * 4 байта ≈ **35 ГБ**.

- **Модели и артефакты:**
  - Two-Tower модель (~500 МБ), эмбеддинги товаров (35 ГБ), версионирование: ~ **50 ГБ**.

**Итого ориентировочный объем хранилища:** **~235 ТБ** (с учетом репликации и запаса).

### **2. Расчёт требований к пропускной способности**

- **Пиковая нагрузка:** **12,051 RPS**.
- **Задержка на запрос:** < **190 мс**.
- **Обработка одного запроса:**
  1. Retrieval (~20 мс)
  2. Загрузка признаков 1000 кандидатов (~50 мс, с кэшем)
  3. Нейросетевой ранжирование (~50 мс)
  *Итого: ~120 мс, укладываемся в лимит.*

- **Требуемое количество инстансов сервиса:**
  - Предположим, один инстанс (Pod с 4 CPU, 16 GB RAM) может обрабатывать **500 RPS**.
  - **12,051 RPS / 500 RPS/инстанс ≈ 25 инстансов**.
  - С учетом отказоустойчивости и пиков (+30%): **~33 инстанса**.

- **Требования к сети на пике:**
  - Входящий трафик (запросы): 12,051 RPS * 1 КБ ≈ **11.8 МБ/с**.
  - Исходящий трафик (ответы, топ-100 товаров ~10 КБ): 12,051 RPS * 10 КБ ≈ **117.7 МБ/с**.

### **3. Масштабируемость и надёжность**

- **Масштабируемость:**
  - **Горизонтальное масштабирование сервисов:** Все ключевые сервисы (Search & Ranking, Retrieval, Feature Store) развернуты в Kubernetes с поддержкой HPA на основе CPU/RPS-метрик.
  - **Масштабирование данных:** Используются распределенные хранилища (S3 для логов, Cassandra/Redis для Feature Store, Elasticsearch для индекса), поддерживающие шардирование.
  - **Асинхронная обработка:** Тяжелые операции (пересчет эмбеддингов, обучение моделей) вынесены в отдельные, масштабируемые пайплайны.

- **Надёжность:**
  - **Репликация и избыточность:** Множественные реплики сервисов и баз данных в разных зонах доступности (AZ).
  - **Health Checks и Self-healing:** Kubernetes выполняет проверки жизнеспособности (liveness/readiness probes) и автоматически перезапускает неисправные поды.
  - **Развертывание без простоя:** Используются стратегии blue-green или canary-развертывания для обновления моделей и сервисов.
  - **Мониторинг и алертинг:** Всеобъемлющий мониторинг (инфраструктура, задержки, ошибки, бизнес-метрики) через Prometheus/Grafana с настройкой алертов в PagerDuty/Slack.
  - **Резервное копирование и восстановление:** Регулярные бэкапы конфигураций, моделей и критичных данных. Восстановление из бэкапа отработано и протестировано.

---

## **Список использованных источников**

1.  Huang, J., et al. (2020). "Embedding-based Retrieval in Facebook Search." *Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining*.
2.  Yi, X., et al. (2019). "Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations." *Proceedings of the 13th ACM Conference on Recommender Systems*.
3.  Qin, T., & Liu, T. Y. (2013). "Introducing LETOR 4.0 Datasets." *CoRR, abs/1306.2597*.
4.  Kubernetes Documentation. [https://kubernetes.io/docs/](https://kubernetes.io/docs/)
5.  Feast: Feature Store for Machine Learning. [https://feast.dev/](https://feast.dev/)
6.  MLflow: A Platform for the Machine Learning Lifecycle. [https://mlflow.org/](https://mlflow.org/)
7.  Mermaid.js Documentation. [https://mermaid.js.org/](https://mermaid.js.org/)
8.  Draw.io Diagrams. [https://app.diagrams.net/](https://app.diagrams.net/)

---

**Примечание:** Все диаграммы были созданы в draw.io и экспортированы в PNG. Каждая диаграмма соответствует требованиям задания и демонстрирует полный цикл работы системы поиска и ранжирования товаров в электронной коммерции.
